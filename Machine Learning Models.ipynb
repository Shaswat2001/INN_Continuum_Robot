{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataset(normalised=True,scaleMethod='Standard'):\n",
    "    '''\n",
    "    Imports Dataset and returns either scaled values depending upon user inputs\n",
    "    \n",
    "    Input:\n",
    "        normalised -- boolean depending upon whether the user wants to scale the values\n",
    "        scaleMethod -- Type of scaler to be used if normalised is True\n",
    "    \n",
    "    Output:\n",
    "        (X_train,X_test,Y_train,Y_test) -- the training and testing dataset\n",
    "        scaler -- used to perform inverse transform if dataset is scaled\n",
    "    '''\n",
    "    data = pd.read_csv('MLDataset.csv')\n",
    "    dataS = data.drop('Unnamed: 0',axis=1)\n",
    "    \n",
    "    if normalised == False:\n",
    "        scaler = 'None'\n",
    "        X = dataS.iloc[:,0:3].values\n",
    "        Y = dataS.iloc[:,3:].values\n",
    "        X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.15,random_state=0)\n",
    "        \n",
    "    elif scaleMethod == 'Standard':\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(dataS)\n",
    "        dataS = scaler.transform(dataS)\n",
    "        X = dataS[:,0:3]\n",
    "        Y = dataS[:,3:]\n",
    "        X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.15,random_state=0)\n",
    "    \n",
    "    \n",
    "    return X_train,X_test,Y_train,Y_test,scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverseTransform(scaler,*arr):\n",
    "    '''\n",
    "    Used to perform Inverse Transformation on normalised dataset\n",
    "    \n",
    "    Input:\n",
    "        scaler -- Instance of Normaliser used\n",
    "        *arr -- list of arrays to be concatenated\n",
    "    '''\n",
    "    data = np.concatenate(arr,axis=1)\n",
    "    data = pd.DataFrame(data)\n",
    "    arrInverse = scaler.inverse_transform(data)\n",
    "    \n",
    "    return arrInverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(y_test,y_pred):\n",
    "    '''\n",
    "    Calculates error of the model\n",
    "    '''\n",
    "    error = (y_test-y_pred)/y_test\n",
    "    error = np.sum(abs(error))/(y_test.shape[0]*y_test.shape[1])*100\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Neighbors Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rscore = {}\n",
    "for normalise in [True,False]:\n",
    "    X_train,X_test,Y_train,Y_test,scaler = import_dataset(normalised=normalise)\n",
    "    for nbr in range(2,100):\n",
    "        for wgt in ['uniform', 'distance']:\n",
    "            Model = KNeighborsRegressor(n_neighbors=nbr,weights=wgt)\n",
    "            Model.fit(X_train,Y_train)\n",
    "            Ytr_pred = Model.predict(X_train)\n",
    "            Yts_pred = Model.predict(X_test)\n",
    "            \n",
    "            if normalise == False:\n",
    "                error = cost(Y_test,Yts_pred)\n",
    "                error_tr = cost(Y_train,Ytr_pred)\n",
    "            else:\n",
    "                true = inverseTransform(scaler,X_train,Y_train)\n",
    "                pred = inverseTransform(scaler,X_train,Ytr_pred)\n",
    "                \n",
    "                error_tr = cost(true[:,3:],pred[:,3:])\n",
    "                \n",
    "                true = inverseTransform(scaler,X_test,Y_test)\n",
    "                pred = inverseTransform(scaler,X_test,Yts_pred)\n",
    "                \n",
    "                error = cost(true[:,3:],pred[:,3:])\n",
    "#             valTst = Model.score(X_test,Y_test)\n",
    "#             val = Model.score(X_train,Y_train)\n",
    "            param = {normalise,nbr,wgt}\n",
    "            Rscore[(error,error_tr)]=param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rscore = {}\n",
    "for normalise in [True,False]:\n",
    "    X_train,X_test,Y_train,Y_test,scaler = import_dataset(normalised=normalise)\n",
    "    for cpt in range(2,4):\n",
    "        for cvr in ['full', 'tied','diag','spherical']:\n",
    "            Model = GaussianMixture(n_components=cpt,covariance_type=cvr)\n",
    "            Model.fit(X_train,Y_train[:,[0]])\n",
    "            Ytr_pred = Model.predict(X_train)\n",
    "            Yts_pred = Model.predict(X_test)\n",
    "            Ytr_pred = Ytr_pred.reshape(Ytr_pred.shape[0],1)\n",
    "            Yts_pred = Yts_pred.reshape(Yts_pred.shape[0],1)\n",
    "            if normalise == False:\n",
    "                error = cost(Y_test[:,[0]],Yts_pred[:,[0]])\n",
    "                error_tr = cost(Y_train[:,[0]],Ytr_pred[:,[0]])\n",
    "            else:\n",
    "                true = inverseTransform(scaler,X_train,Y_train)\n",
    "                pred = inverseTransform(scaler,X_train,Ytr_pred,Y_train[:,1:])\n",
    "                \n",
    "                error_tr = cost(true[:,3:],pred[:,3:])\n",
    "                \n",
    "                true = inverseTransform(scaler,X_test,Y_test)\n",
    "                pred = inverseTransform(scaler,X_test,Yts_pred,Y_test[:,1:])\n",
    "                \n",
    "                error = cost(true[:,3:],pred[:,3:])\n",
    "#             valTst = Model.score(X_test,Y_test)\n",
    "#             val = Model.score(X_train,Y_train)\n",
    "            param = {normalise,cpt,cvr}\n",
    "            Rscore[(error,error_tr)]=param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
